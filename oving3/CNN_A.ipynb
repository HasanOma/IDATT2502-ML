{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b14570-c328-407e-ba9e-2e464cc7a282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T12:27:25.806048Z",
     "iopub.status.busy": "2022-09-12T12:27:25.805535Z",
     "iopub.status.idle": "2022-09-12T12:27:26.068071Z",
     "shell.execute_reply": "2022-09-12T12:27:26.067460Z",
     "shell.execute_reply.started": "2022-09-12T12:27:25.806028Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# Load observations from the mnist dataset. The observations are divided into a training set and a test set\n",
    "mnist_train = torchvision.datasets.MNIST('./data', train=True, download=True)\n",
    "train_x = mnist_train.data.reshape(-1, 1, 28, 28).float()  # torch.functional.nn.conv2d argument must include channels (1)\n",
    "train_y = torch.zeros((mnist_train.targets.shape[0], 10))  # Create output tensor\n",
    "train_y[torch.arange(mnist_train.targets.shape[0]), mnist_train.targets] = 1  # Populate output\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('./data', train=False, download=True)\n",
    "test_x = mnist_test.data.reshape(-1, 1, 28, 28).float()  # torch.functional.nn.conv2d argument must include channels (1)\n",
    "test_y = torch.zeros((mnist_test.targets.shape[0], 10))  # Create output tensor\n",
    "test_y[torch.arange(mnist_test.targets.shape[0]), mnist_test.targets] = 1  # Populate output\n",
    "\n",
    "# Normalization of inputs\n",
    "mean = train_x.mean()\n",
    "std = train_x.std()\n",
    "train_x = (train_x - mean) / std\n",
    "test_x = (test_x - mean) / std\n",
    "\n",
    "# Divide training data into batches to speed up optimization\n",
    "batches = 600\n",
    "x_train_batches = torch.split(train_x, batches)\n",
    "y_train_batches = torch.split(train_y, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "758d738a-31bc-49d0-97d4-1ccdea44b117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T12:45:16.927476Z",
     "iopub.status.busy": "2022-09-12T12:45:16.926843Z",
     "iopub.status.idle": "2022-09-12T12:45:16.932239Z",
     "shell.execute_reply": "2022-09-12T12:45:16.931850Z",
     "shell.execute_reply.started": "2022-09-12T12:45:16.927452Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.logits = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, padding=2), # Applies a 2D convolution over an input signal composed of several input planes.\n",
    "            nn.MaxPool2d(kernel_size=2), # Applies a 2D max pooling over an input signal composed of several input planes.\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2), # Applies a 2D convolution over an input signal composed of several input planes.\n",
    "            nn.MaxPool2d(kernel_size=2),  # Applies a 2D max pooling over an input signal composed of several input planes.\n",
    "            nn.Flatten(), # Flattens a contiguous range of dims into a tensor\n",
    "            nn.Linear(64 * 7 * 7, 10)) #Linear transforms\n",
    "\n",
    "    # Predictor\n",
    "    def f(self, x):\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    # Cross Entropy loss\n",
    "    def loss(self, x, y):\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))\n",
    "\n",
    "    # Accuracy\n",
    "    def accuracy(self, x, y):\n",
    "        return torch.mean(torch.eq(self.f(x).argmax(1), y.argmax(1)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99fc589e-94fa-4d75-9f31-b145a6ffa078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T12:45:18.250345Z",
     "iopub.status.busy": "2022-09-12T12:45:18.249725Z",
     "iopub.status.idle": "2022-09-12T12:48:05.523700Z",
     "shell.execute_reply": "2022-09-12T12:48:05.523119Z",
     "shell.execute_reply.started": "2022-09-12T12:45:18.250321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = tensor(0.9725)\n",
      "accuracy = tensor(0.9810)\n",
      "accuracy = tensor(0.9830)\n",
      "accuracy = tensor(0.9841)\n",
      "accuracy = tensor(0.9851)\n",
      "accuracy = tensor(0.9837)\n",
      "accuracy = tensor(0.9819)\n",
      "accuracy = tensor(0.9816)\n",
      "accuracy = tensor(0.9832)\n",
      "accuracy = tensor(0.9839)\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "\n",
    "# Optimize: adjust W and b to minimize loss using stochastic gradient descent\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "for epoch in range(10):\n",
    "    for batch in range(len(x_train_batches)):\n",
    "        model.loss(x_train_batches[batch], y_train_batches[batch]).backward()  # Compute loss gradients\n",
    "        optimizer.step()  # Perform optimization by adjusting W and b,\n",
    "        optimizer.zero_grad()  # Clear gradients for next step\n",
    "\n",
    "    print(\"accuracy = %s\" % model.accuracy(test_x, test_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ce388-bd53-467d-9e81-28811903a636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
